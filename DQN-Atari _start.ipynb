{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DQN-Atari _start.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMEuNZVr1KJ2ZKP0qGz9Tb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## Installs"],"metadata":{"id":"qSKTzGP9OzsN"}},{"cell_type":"code","source":["%%capture\n","!apt install python-opengl # Python binding to OpenGL and related APIs\n","!pip install pyglet==1.5.1 \n","!apt install python-opengl\n","!apt install ffmpeg\n","!apt install xvfb\n","!pip3 install pyvirtualdisplay\n","\n","# Virtual display\n","from pyvirtualdisplay import Display\n","\n","virtual_display = Display(visible=0, size=(1400, 900))\n","virtual_display.start()"],"metadata":{"id":"uPG6NoQ2Oy5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install ale-py==0.7.4   # To overcome an issue with Gym (https://github.com/DLR-RM/stable-baselines3/issues/875)\n","# https://stackoverflow.com/questions/69442971/error-in-importing-environment-openai-gym\n","!pip install gym[atari,accept-rom-license]==0.21.0"],"metadata":{"id":"iKBon-YfQP5I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657968456571,"user_tz":-60,"elapsed":26793,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"464704f5-3770-4cc0-fb58-32c421d1db2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gym[accept-rom-license,atari]==0.21.0\n","  Downloading gym-0.21.0.tar.gz (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 18.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]==0.21.0) (1.21.6)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]==0.21.0) (1.3.0)\n","Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]==0.21.0) (4.12.0)\n","Collecting ale-py~=0.7.1\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 54.4 MB/s \n","\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.1->gym[accept-rom-license,atari]==0.21.0) (5.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (4.64.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (7.1.2)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym[accept-rom-license,atari]==0.21.0) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym[accept-rom-license,atari]==0.21.0) (4.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (2022.6.15)\n","Building wheels for collected packages: gym, AutoROM.accept-rom-license\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616825 sha256=f5a8a0adc6f7ff5e5345b592496ae5f1657cee9a265f06d7277b46c570b4c268\n","  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=fece20b0939f043542345c6f7fa066dc68d9b29af80441aae9a2d73e4320041d\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built gym AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, gym, ale-py\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.17.3\n","    Uninstalling gym-0.17.3:\n","      Successfully uninstalled gym-0.17.3\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2 gym-0.21.0\n"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"b4qPgO8WO9nJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFh7vFtnME13"},"outputs":[],"source":["import torch\n","import numpy as np\n","import cv2\n","\n","import gym"]},{"cell_type":"markdown","source":["## Inspect the Environment"],"metadata":{"id":"v04wvMAgQnJP"}},{"cell_type":"code","source":["ENV_NAME = \"BreakoutNoFrameskip-v4\"\n","env = gym.make(ENV_NAME)"],"metadata":{"id":"mDnzTyo8Qk7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env.observation_space.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BMBVIHrlRmaK","executionInfo":{"status":"ok","timestamp":1657968459637,"user_tz":-60,"elapsed":166,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"77b8d9ce-67db-4046-86ef-801965b2483d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(210, 160, 3)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["env.action_space.n, env.action_space.sample()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-eRSC9CU_vx","executionInfo":{"status":"ok","timestamp":1657968459642,"user_tz":-60,"elapsed":168,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"8e878e41-4d38-4bcd-bef0-47dde85c4254"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 1)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["obs = env.reset()"],"metadata":{"id":"PCnjAZb6VGDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display\n","from PIL import Image, ImageOps\n","\n","image = Image.fromarray(obs, mode=\"RGB\")\n","display(image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"id":"EnEQgdVRVbn5","executionInfo":{"status":"ok","timestamp":1657968459656,"user_tz":-60,"elapsed":170,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"a7bfaebb-99a9-4bd5-b105-0c6b47fcde9e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=160x210 at 0x7FBEB8794210>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAACu0lEQVR4nO3dsW0TYRiA4QS5RkxARcEIEQNYLpjGEzCBx0AMQGGloEQZBlEgRJEiygL+IZZ9d/bL85Sn090vvfl8v+SzcnMDAMDZ3c55s91u989zttvtbOcfa+rrj+51yjVfnWMxXK7VUjeec1Jfcv6xzjWpUzPBcYtN8LUbfSpc2mSb4DgTfITRdE7xjD8XExy32AQf+1c/9flLXXNqJhjgYt1e43OFl/MMjhM4TuA4geMEjhM4TuA4geMEjhM4TuA4geMEjhM4bvjKzqW9/snfjb72NcFxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdw3PDF94fNZs51cKLvg+MmOE7gOIHjBI4TOG64i35692vOdTARExwncJzAcQLHCRw33EX/fP1nznUwERMcJ3CcwHECxwkcN95Fv3+ccx2c6sfhwyY4TuA4geMEjhM4briL/vz0ds51cKL14LgJjhM4TuA4geMEjhvuoh+/fJpxGZxsffj3hSY4TuA4geMEjhM4briL/ra/m3MdnOjj2j+n/C8JHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdw3Orrm99Lr+E6PGw2R51/t99PtJKDPtzfHzxuguMEjhM4brX0Aq7GzM/UczHBcSY44ko/YAAAAAAAAFjUMyEkRxlHStXAAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"code","source":["from IPython.display import clear_output\n","\n","rews = []\n","for i in range(1000):\n","  obs, rew, done, info = env.step(env.action_space.sample())\n","  clear_output(wait=True)\n","  display(Image.fromarray(obs, mode=\"RGB\"))\n","  rews.append(rew)\n","  if done:\n","    env.reset()\n","\n","print(rews[-20:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"Qe2tFKmhVhD3","executionInfo":{"status":"ok","timestamp":1657968472326,"user_tz":-60,"elapsed":12831,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"965c73b6-4a5e-4bf6-d9c3-5ecae46ee65c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=160x210 at 0x7FBEB879D1D0>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAACn0lEQVR4nO3dMW4TQRiA0QS5RpyAioIjRBzAcsFpfAJO4GNEHIDCSkGJchhEgRBFioiWwqPEXu/GfLxXrsbekT792ZFiy1dXAACc3fWSN9vtdk+u2W63i62f4u97nes953j/V+fYDJdr9VI3XnJSn7O+ygTHCRwncJzAcQLHvdgp+tiT7dzrq0wwwMW69qxq8wyOEzhO4DiB4wSOEzhO4DiB4wSOEzhO4DiB4wSOEzhu+JGdOb6OwXxG//Y1wXECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3Dc8IPv95vNkvtgom+D6yY4TuA4geMEjhM4bniKfnz3c8l9MBMTHCdwnMBxAscJHDc8Rf94/XvJfTATExwncJzAcQLHCRw3PkW/f1hyH0z1/fBlExwncJzAcQLHCRw3PEXfPr5dch9MtB5cN8FxAscJHCdwnMBxw1P0w+dPC26DydaHv19oguMEjhM4TuA4geOGp+iv+5sl98FEH9d+nPK/JHCcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHGrL29+nfCy+83mqPU3+/0Jd+H5PtzdHbxuguMEjhM4bnXayzxT/xUmOO7ECebS+JsKAAAAAADA8f4Az3w+Faa5HhgAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"]}]},{"cell_type":"code","source":["# Convert to Grayscale\n","grayscale_image = ImageOps.grayscale(image)\n","grayscale_image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"id":"XUvOb4lFb-nb","executionInfo":{"status":"ok","timestamp":1657968472333,"user_tz":-60,"elapsed":103,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"ae6c277c-5dea-4077-cc22-155ef15cb97a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PIL.Image.Image image mode=L size=160x210 at 0x7FBEB86A8D10>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAAAAADoTpQ7AAABlElEQVR4nO3dMW7CQBBA0SXiAiSn4VIpchCKXCMnSpeSlpaKxkwQ2rU3/MCO0H+NsWzkz8grmQZKkTRr1XPS7uL1R8f+0vtb16gde+kJHGnde2LP5HalrTW5Jc8zQeo83b9O0gmW8ju1uXu05XkmeP3pl/Z7jy1JP0FRK3J/PEL6e9BAykDKQMpAykDKQCp9YDzy3/rF+l7Oj4HpJ2ggZSBlIGUgZSBlIGUgZSBlIGUgZSCVPjC+uL+PrJiRfoIGUgZSsYrfRlbMSD9BAykDqVjFWUuzdgUDKQOpWMWbkRUVx2mbfoIGUgZSsYr3IysqXqdt+gkaSBlIxSr+HllRsZ226SdoIGUgFav4a2RFhav4vxhIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIGUgZSBlIpQ9cH+5/jeuf1/zsedPPtE0/QQOpR/zrZNc91+IEb4XGLkmSlMYJLZQYQvkKbKQAAAAASUVORK5CYII=\n"},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Downsampling\n","scaled_image = grayscale_image.resize((84, 110))\n","scaled_image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":127},"id":"fix6HIWZZ9Bg","executionInfo":{"status":"ok","timestamp":1657968472339,"user_tz":-60,"elapsed":103,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"0f1b2f4c-8af0-4087-8116-bcaae4dbdee4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PIL.Image.Image image mode=L size=84x110 at 0x7FBEB871EB90>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAFQAAABuCAAAAACc4WvWAAACb0lEQVR4nO2ZS2sTURTH//cxiaZGQwSxNWJURKyKC3du20Vx5UIQ3LjyOwiuXLjST9Cli+JnUNy5LIgFKdRYEmttNYyPtHHymLnXxTw1k1c5WaTcPySTm/O/v5w5c2dykgGmRaz3rex1LuHiQ/NSkXGlv1ULl7WE6773QseZEgR4Yy0xqTxX244Gshd67IFe967knjYXb36yT597Uy09/PkxM99cd0LHjbtbNfDvSeitpZcDobrrLHuPZzW66vXq4lkXyt1ezj/pJBzYeau9dnKS2/biQQoUAPf8svCoPDwZrr/jSzPlyrPUuX2gwrrQzgoGzk+VT3IOJnLl41LEho1djYvn9T9pyMTHpkA7n/kdNPZbqFfmr+qKjeamew9fHDdyXFvoQG/uJifZ1V/xgBVTUtUs/dFj6jNkz1OYfiTaxi/+d/SBJktFJqmHe8YWH245zFAZPRHJDXis1h5mHVnZkvahfGWHDDr7yAtqSrj7Epimo2+gBjoJqKLjKSA4rQrOYOcYKoRQdbuV0lIdSPqIwiQv0oxRZep/bUsAOp+jYkJoRJmSQRkw0ZrSoSecqabrfXQEnSFj+lS/maArguoiqCndiooXP/bpLlM8E0KdLtkFxYqgXJBB446n4ZBBj+YDKLN/Ux1+dSLs+iAsMqgAgkzrP8h2v8iCTNnqVyImMLeAYPET/pYSwNQ1EwZqoAZqoAZqoAZqoAZqoAZqoAZqoIcNKnV4a3V0sUyw7Xq9QaUAuQeIlNggZe9nNABYrzZ6Yp0tdcBMrQCaVjulAGkB4/7V1VrxJ7A/fQxyDeBj3jvQe/1j9ovxWEZGo+gvB22zPDZs1wcAAAAASUVORK5CYII=\n"},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Crop 84 x 84 game area\n","cropping_area = (0, 17, 0, 9)\n","cropped_image = ImageOps.crop(scaled_image, cropping_area)\n","print(cropped_image.size)\n","cropped_image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118},"id":"1yzJR-IUbJof","executionInfo":{"status":"ok","timestamp":1657974669129,"user_tz":-60,"elapsed":338,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"01480dc8-d9cd-4322-a6b0-a724310fe303"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(84, 84)\n"]},{"output_type":"execute_result","data":{"text/plain":["<PIL.Image.Image image mode=L size=84x84 at 0x7FD25E996F90>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAFQAAABUCAAAAAA5AE8dAAABHElEQVR4nO3YTUrEQBCG4bfTnfjH4OBO8TbuPIIn8QiuPJBn8ARuBV2Igj8QMUy1i3SSxQyC8mUxUrXJouHhS3WlaRKuIV49oqrjyxVUAElm9lSl86Zy1NGtQU3nGZTPatnK0OWA2vlnEJl515ippwkgBFVSwoDmxb7KJGbGpDI0wKw91dEzJ81Z5uURPZCZvZoAkq4J1lF6qpuoafj50B1TVTOgbSc7UOoRraIMnW48b60M3VsUNDy/qrbfDk9zSRprGRqhJH16kb3+UShJw+2DyISTM8rwR5nZU1t2mXDUUUcdddRRRx111FFHHXXU0f+Gplz+z/2iQlOe3Wp90QzSO8QNaz/VzkWTAeqbu7W1r3v7Y9K6oJt6ZwbfnIQ60CUlZ5EAAAAASUVORK5CYII=\n"},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["## HyperParameters"],"metadata":{"id":"x0_GQ3naE7UR"}},{"cell_type":"code","source":["SEED = 0\n","LEARNING_RATE = 1e-4\n","WEIGHT_DECAY = 5e-4\n","NUM_FRAMES = 4\n","TRAIN_FREQ = 4\n","UPDATE_TARGET_Q_FREQ = 1000\n","TOTAL_TIMESTEPS = 1e6\n","EPSILON_START = 1\n","EPSILON_END = 0.01\n","EPSILON_DROP_FRACTION = 0.1 # fraction of total timesteps to reduce epsilon, 1e6th frame\n","TRAINING_STARTS = 1e5\n","BATCH_SIZE = 32\n","GAMMA = 0.99\n","REPLAY_BUFFER_LENGTH = 1e5\n","LOG_EPISODE_FREQ = 25\n","FRAME_SKIP = 4\n","NO_OP_MAX = 30  # TODO: max no of 'do nothing' actions to be performed by an agent at the start of an episode"],"metadata":{"id":"cuEcKlJ-E_SW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GPU UTILITIES"],"metadata":{"id":"Tg6P6FW6F9b2"}},{"cell_type":"code","source":["device = torch.device(\"cpu\")\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jh1JHTZsGF14","executionInfo":{"status":"ok","timestamp":1657974669664,"user_tz":-60,"elapsed":17,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"82b82a03-2b9c-49df-c678-4e6d82815df0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["## Q-Network"],"metadata":{"id":"EC71fGEVjpyY"}},{"cell_type":"code","source":["import torch.nn as nn\n","\n","model = nn.Sequential(nn.Conv2d(in_channels=4, out_channels=16, kernel_size=(8,8), stride=4),\n","                      nn.ReLU(),\n","                      nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(4,4), stride=2),\n","                      nn.ReLU(),\n","                      nn.Flatten(),\n","                      nn.Linear(2592, 256),\n","                      nn.Linear(256, 4)).to(device)\n","\n","\n","model_opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"],"metadata":{"id":"PPG6KPnvjvyE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DQN Algorithm"],"metadata":{"id":"0mp1gOEHkCzc"}},{"cell_type":"markdown","source":["### Preprocessing Function"],"metadata":{"id":"Vbk4pKq0Gx6u"}},{"cell_type":"code","source":["def preprocess_sequence(seq, n_frames=NUM_FRAMES):\n","  if len(seq) < n_frames:\n","    [seq.append(seq[-1]) for _ in range(n_frames-len(seq))]\n","\n","  res = []\n","  for i in range(-n_frames, 0):\n","    arr = seq[i]\n","    img = Image.fromarray(arr)\n","    img = ImageOps.grayscale(img)\n","    img = img.resize((84, 110))\n","    img = ImageOps.crop(img, (0, 17, 0, 9))\n","    res.append(np.asarray(img)/255.0)iwiooqowowqwqwqwqwq\n","    # del arr\n","    # del img\n","  return np.array(res)"],"metadata":{"id":"DV5ooLSoeBu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq = []\n","for i in range(1000):\n","  obs, rew, done, info = env.step(env.action_space.sample())\n","  seq.append(obs)\n","  if done:\n","    env.reset()\n","\n","input = torch.tensor(preprocess_sequence(seq, NUM_FRAMES), dtype=torch.float32)\n","input.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5XM9RUagQoO","executionInfo":{"status":"ok","timestamp":1657974670198,"user_tz":-60,"elapsed":16,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"a173d7b1-9e28-499e-ebfd-57f25d358976"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 84, 84])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["model(input.unsqueeze(0).to(device)).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t8I0p6HWlAHh","executionInfo":{"status":"ok","timestamp":1657974670198,"user_tz":-60,"elapsed":13,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"0a020328-4eed-430d-f3d1-89a4622e27b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 4])"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["### Gradient Descent"],"metadata":{"id":"hb8QNZKUG_hk"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","def fit(model, opt, input, target, loss_fn=F.huber_loss, grad_clip=None):\n","  out = model(input)\n","  pred_val, _ = torch.max(out, dim=1)\n","  loss = loss_fn(pred_val, target)\n","\n","  # Compute the gradient\n","  loss.backward()\n","\n","  # Clip Gradient\n","  if grad_clip:\n","    nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","\n","  # Perform a gradient descent step\n","  opt.step()\n","  opt.zero_grad()\n","\n","  return loss.item()"],"metadata":{"id":"GdAZd3M9HDTp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Greedy, Epsilon-Greedy Policy"],"metadata":{"id":"aY6VcNGUofDk"}},{"cell_type":"code","source":["def greedy_policy(model, obs):\n","    return torch.argmax(model(obs.unsqueeze(0)), dim=1)\n","\n","def epsilon_greedy_policy(model, obs, epsilon):\n","  if np.random.uniform() < epsilon:\n","    return env.action_space.sample()\n","  else:\n","    return torch.argmax(model(obs.unsqueeze(0)), dim=1)"],"metadata":{"id":"Ps14mI3LPDUl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Main Algorithm"],"metadata":{"id":"8elQ6oUPMJBu"}},{"cell_type":"code","source":["def append_to_buffer(buffer, timestep, data, max_size):\n","  if(len(buffer) >= max_size):\n","    buffer[int(timestep % max_size)] = data\n","  else:\n","    buffer.append(data)"],"metadata":{"id":"_Hq1cY9wnoDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import copy\n","import random\n","from collections import deque\n","import sys\n","import gc\n","import psutil\n","\n","# Initialize replay buffer\n","replay_buffer = deque()\n","\n","# Initialize target_q_network\n","target_q = copy.deepcopy(model)\n","\n","timestep = 0\n","\n","episode_number = 0\n","episode_returns = []\n","episode_mean_losses = []\n","\n","while True:\n","  obs = env.reset()\n","  sequence = deque()\n","  sequence.append(obs)\n","  # Wrapper: Raw Observation Preprocessing\n","  preprocessed = preprocess_sequence(sequence) # Let preprocess scale [0,255] to [0,1]\n","\n","  episode_return = 0\n","  losses = []\n","\n","  done = False\n","  while not done:\n","    epsilon = EPSILON_START - (EPSILON_START - EPSILON_END)*(timestep/(TOTAL_TIMESTEPS*EPSILON_DROP_FRACTION))\n","    epsilon = max(epsilon, EPSILON_END)\n","    action = epsilon_greedy_policy(model, torch.tensor(preprocessed, dtype=torch.float32, device=device), epsilon)\n","\n","    # Take action and store transition in replay buffer\n","    # Wrapper: Frameskipping\n","    rew = 0\n","    for _ in range(FRAME_SKIP or 1):\n","      obs, frame_rew, done, _ = env.step(action)\n","      rew += frame_rew\n","      if done: break\n","\n","    # Wrapper: Reward Modification\n","    if rew < 0: rew = -1\n","    if rew > 0: rew = 1\n","    \n","    episode_return += rew\n","    append_to_buffer(seq, timestep, obs, NUM_FRAMES) #seq.append(obs)\n","    next_preprocessed_sequence = preprocess_sequence(sequence)\n","    transition = (preprocessed, action, rew, next_preprocessed_sequence, done)\n","    append_to_buffer(replay_buffer, timestep, transition, REPLAY_BUFFER_LENGTH) #replay_buffer.append(transition)\n","    # del preprocessed\n","    preprocessed = next_preprocessed_sequence\n","\n","    # Increment Timestep, pop frame sequence and replay buffer\n","    timestep += 1\n","    # if len(replay_buffer) > REPLAY_BUFFER_LENGTH:\n","    #   del replay_buffer[0]\n","    # if len(sequence) > NUM_FRAMES:\n","    #   del sequence[0]\n","\n","    # Compute Targets and Perform a Gradient descent step\n","    if (timestep >= TRAINING_STARTS) and not (timestep % TRAIN_FREQ):\n","      # Sample a mini-batch from the replay buffer\n","      batch = random.sample(replay_buffer, BATCH_SIZE)\n","      states = torch.tensor(np.array([x[0] for x in batch]), dtype=torch.float32, device=device)\n","      rews = torch.tensor([x[2] for x in batch], dtype=torch.float32, device=device)\n","      next_states = torch.tensor(np.array([x[3] for x in batch]), dtype=torch.float32, device=device)\n","      not_dones = torch.tensor([not x[4] for x in batch], dtype=torch.bool, device=device)\n","\n","      # Compute TD targets\n","      td_targets = rews + not_dones*GAMMA*torch.max(target_q(next_states), dim=1)[0]\n","\n","      # Perform Gradient Descent\n","      loss = fit(model, model_opt, states, td_targets, F.huber_loss)\n","      losses.append(loss)\n","\n","    # Update the Target Q Network\n","    if not (timestep % UPDATE_TARGET_Q_FREQ):\n","      # del target_q\n","      target_q = copy.deepcopy(model)\n","      # gc.collect()\n","\n","    if done:\n","      append_to_buffer(episode_returns, episode_number, episode_return, LOG_EPISODE_FREQ)\n","      # episode_returns.append(episode_return)\n","      append_to_buffer(episode_mean_losses, episode_number, np.mean(losses), LOG_EPISODE_FREQ)\n","      # episode_mean_losses.append(np.mean(losses))\n","      episode_number += 1\n","\n","      if not (episode_number % LOG_EPISODE_FREQ):\n","        print(f\"Episode [{episode_number}] Mean Return: {np.mean(episode_returns):.2f} Mean Loss: {np.mean(episode_mean_losses):.2f} Timestep: {timestep} Epsilon: {epsilon:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":936},"id":"62K_xTsPKROp","outputId":"ab214c6e-2a15-4305-de9e-be2a8814dc66","executionInfo":{"status":"error","timestamp":1657978167712,"user_tz":-60,"elapsed":3497521,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"]},{"output_type":"stream","name":"stdout","text":["Episode [25] Mean Return: 1.16 Mean Loss: nan Timestep: 4534 Epsilon: 0.96\n","Episode [50] Mean Return: 0.92 Mean Loss: nan Timestep: 8833 Epsilon: 0.91\n","Episode [75] Mean Return: 1.28 Mean Loss: nan Timestep: 13596 Epsilon: 0.87\n","Episode [100] Mean Return: 0.84 Mean Loss: nan Timestep: 17962 Epsilon: 0.82\n","Episode [125] Mean Return: 1.28 Mean Loss: nan Timestep: 22805 Epsilon: 0.77\n","Episode [150] Mean Return: 1.04 Mean Loss: nan Timestep: 27352 Epsilon: 0.73\n","Episode [175] Mean Return: 0.92 Mean Loss: nan Timestep: 31863 Epsilon: 0.68\n","Episode [200] Mean Return: 0.8 Mean Loss: nan Timestep: 36327 Epsilon: 0.64\n","Episode [225] Mean Return: 1.2 Mean Loss: nan Timestep: 41148 Epsilon: 0.59\n","Episode [250] Mean Return: 1.08 Mean Loss: nan Timestep: 46090 Epsilon: 0.54\n","Episode [275] Mean Return: 0.72 Mean Loss: nan Timestep: 50643 Epsilon: 0.50\n","Episode [300] Mean Return: 0.8 Mean Loss: nan Timestep: 55473 Epsilon: 0.45\n","Episode [325] Mean Return: 0.72 Mean Loss: nan Timestep: 60163 Epsilon: 0.40\n","Episode [350] Mean Return: 0.72 Mean Loss: nan Timestep: 65026 Epsilon: 0.36\n","Episode [375] Mean Return: 0.52 Mean Loss: nan Timestep: 69910 Epsilon: 0.31\n","Episode [400] Mean Return: 0.36 Mean Loss: nan Timestep: 75006 Epsilon: 0.26\n","Episode [425] Mean Return: 0.48 Mean Loss: nan Timestep: 80547 Epsilon: 0.20\n","Episode [450] Mean Return: 0.16 Mean Loss: nan Timestep: 86479 Epsilon: 0.14\n","Episode [475] Mean Return: 0.12 Mean Loss: nan Timestep: 94086 Epsilon: 0.07\n","Episode [500] Mean Return: 0.68 Mean Loss: nan Timestep: 106731 Epsilon: 0.01\n","Episode [525] Mean Return: 4.12 Mean Loss: 0.0015424250442990822 Timestep: 162331 Epsilon: 0.01\n","Episode [550] Mean Return: 2.24 Mean Loss: 0.0007998514285268049 Timestep: 199905 Epsilon: 0.01\n","Episode [575] Mean Return: 0.12 Mean Loss: 0.000634994907427679 Timestep: 255515 Epsilon: 0.01\n","Episode [600] Mean Return: 0.2 Mean Loss: 0.00020507912401065786 Timestep: 307234 Epsilon: 0.01\n","Episode [625] Mean Return: 0.28 Mean Loss: 4.666124447208977e-05 Timestep: 354251 Epsilon: 0.01\n","Episode [650] Mean Return: 0.28 Mean Loss: 9.023614694609293e-05 Timestep: 407577 Epsilon: 0.01\n","Episode [675] Mean Return: 0.04 Mean Loss: 4.561441933752647e-05 Timestep: 456969 Epsilon: 0.01\n","Episode [700] Mean Return: 0.04 Mean Loss: 2.031263972752055e-05 Timestep: 518990 Epsilon: 0.01\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-6a064f7fe8cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0;31m# Perform Gradient Descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuber_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m       \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-eb1853957667>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, opt, input, target, loss_fn, grad_clip)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mpred_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# Clip Gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# https://imageio.readthedocs.io/en/stable/examples.html#writing-videos-with-ffmpeg-and-vaapi\n","# EP 110 40.7\n","# EP 170 48.3\n","# EP 230 55.5\n","# EP 300 63.1"],"metadata":{"id":"tPvaXejSuWAH"},"execution_count":null,"outputs":[]}]}